{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35cdb27f",
   "metadata": {},
   "source": [
    "# Versionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b68d1",
   "metadata": {},
   "source": [
    "V2: \n",
    "<ul>\n",
    "    <li>Inclusão da variável categórica x28 que está relacionada com o tipo de papel em produção</li>\n",
    "    <li>Feature Selection</li>\n",
    "    <li>Feature Scalling</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af147a2",
   "metadata": {},
   "source": [
    "# O problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5640d24",
   "metadata": {},
   "source": [
    "Paper manufacturing can be viewed as a continuous rolling process. During this process, sometimes the paper breaks. If a break happens, the entire process is stopped, the reel is taken out, any found problem is fixed, and the production is resumed. The resumption can take more than an hour.\n",
    "\n",
    "The cost of this lost production time is significant for a mill. Even a 5% reduction in the break events will give a significant cost saving for a mill. The objective of the given problem is to predict such breaks in advance (early prediction) and identify the potential cause(s) to prevent the break. \n",
    "\n",
    "To build such a prediction model, we will use the data collected from the network of sensors in a mill."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da647642",
   "metadata": {},
   "source": [
    "This is a multivariate time series data with break as the response (a\n",
    "binary variable).\n",
    "The provided data has,\n",
    "<ul>\n",
    "    <li>18,398 records.</li>\n",
    "    <li>Columns:</li>\n",
    "        <ul>\n",
    "        <li>time: the timestamp of the row</li>\n",
    "        <li>y: the binary response variable. There are only 124 rows with y = 1, rest are y = 0.</li>\n",
    "        <li>x1-x61: predictor variables. All the predictors are continuous variables, except x28 and x61. x61 is a binary variable, and x28 is a\n",
    "        categorical variable. All the predictors are centered. Besides, the predictors are a mixture of raw materials and process variables. Their descriptions are omitted for data anonymity.\n",
    "            Several sensors are placed in different parts of the machine along its length\n",
    "and breadth. These sensors measure both raw materials (e.g. amount of pulp\n",
    "fiber, chemicals, etc.) and process variables (e.g. blade type, couch vacuum,\n",
    "rotor speed, etc.).</li>\n",
    "        </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e887af",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011b14",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0806f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbdatafile = '..\\\\data\\\\processminer-rare-event-mts-data.csv'\n",
    "pwbds = pd.read_csv(pwbdatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b202b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db180f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d21878",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de18b57",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1969d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCategorical(yvar):   \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['text.color'] = '#909090'\n",
    "    plt.rcParams['axes.labelcolor']= '#909090'\n",
    "    plt.rcParams['xtick.color'] = '#909090'\n",
    "    plt.rcParams['ytick.color'] = '#909090'\n",
    "    plt.rcParams['font.size']=12\n",
    "    labels = yvar.value_counts().keys()\n",
    "    percentages = list (map(lambda x:round(x*100,2),yvar.value_counts().values/pwbds.shape[0]))\n",
    "    ax.pie(percentages, labels=labels,  \n",
    "           autopct='%1.0f%%', \n",
    "           shadow=False, startangle=0,   \n",
    "           pctdistance=1.2,labeldistance=1.4)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(\"Distribution\")\n",
    "    ax.legend(frameon=False, bbox_to_anchor=(1.5,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c4c9a",
   "metadata": {},
   "source": [
    "The change in the level of the categorical variable, x28, may be more important than its actual value. This variable is related to the type of paper produced at that time. For this prediction model, it might be more important to capture any change in the paper type instead of the actual type of the paper.\n",
    "May consider adding a feature capturing the change in x28, e.g. x28t − x28t−1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bfda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(pwbds['x28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCategorical(pwbds['x61'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A distribuição de x61 indica que podemos descartá-la no processo\n",
    "pwbds.drop('x61',axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae918d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the target\n",
    "pwbds.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f8111",
   "metadata": {},
   "source": [
    "123 registros de quebra da teia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(0.8 * pwbds.shape[0])\n",
    "y_test = pwbds.y[train_ind:]\n",
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76c591",
   "metadata": {},
   "source": [
    "Haverá 34 eventos de quebra no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pwbds['date'] = pwbds['time'].str.split(' ').str[0]\n",
    "#pwbds['time'] = pwbds['time'].str.split(' ').str[1]\n",
    "pwbds['time']= pd.to_datetime(pwbds['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8b63a",
   "metadata": {},
   "source": [
    "## Check total downtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDownTime(ds):\n",
    "    dstmp = ds.copy()\n",
    "    dstmp[\"next_measure\"] = dstmp[\"time\"].shift(-1)\n",
    "    dstmp['downtime'] = dstmp['next_measure'] - dstmp['time']\n",
    "    downtimes = dstmp.loc[dstmp['y']==1][['time', 'downtime']].copy()\n",
    "    return (dstmp.groupby(['y'])['downtime'].agg('sum').iloc[1,],downtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab366b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPeriod = pwbds.tail(1)['time'].iloc[0,] - pwbds.head(1)['time'].iloc[0,]\n",
    "totalDowntime,dtds = calcDownTime(pwbds)\n",
    "perc = round ((totalDowntime/totalPeriod)*100,2)\n",
    "print ('Downtime total de:', totalDowntime, 'num período de: ', totalPeriod, 'correspondendo a: ',perc,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628aeaa8",
   "metadata": {},
   "source": [
    "## Breaks per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtds['time'] = dtds['time'].astype(str)\n",
    "dtds['time'] = dtds['time'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine max_slots\n",
    "max_slots = dtds.time.value_counts().max()\n",
    "slot_size = len(dtds.time.value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtds['downtime']=dtds['downtime'].dt.total_seconds()/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ce9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta numero de listas correspondentes à max_slots, de tamanho correspondente ao número de dias\n",
    "downtime_matrix = np.zeros([max_slots,slot_size])\n",
    "day_idx=0\n",
    "reg_idx=0\n",
    "lista_idx=-1\n",
    "last_day = dtds['time'].iloc[0,]\n",
    "for day in dtds['time'].tolist():\n",
    "    if (day != last_day):\n",
    "        lista_idx=0\n",
    "        last_day = day\n",
    "        day_idx+=1\n",
    "    else:\n",
    "        lista_idx+=1\n",
    "    downtime_matrix[lista_idx,day_idx]=dtds.downtime.iloc[reg_idx,]\n",
    "    reg_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c21496",
   "metadata": {},
   "outputs": [],
   "source": [
    "downtimedf = pd.DataFrame (downtime_matrix.T)\n",
    "downtimedf['day'] = dtds.time.value_counts().sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad569e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "downtimedf = downtimedf.set_index('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38fed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downtimedf.plot(kind=\"bar\",stacked=True, legend=None,figsize=(20, 10))\n",
    "plt.title(\"Downtime Occurencies\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Downtime minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6bbed",
   "metadata": {},
   "source": [
    "## Comportamento de cada feature no tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6672f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'y','x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x12','x13','x14','x15','x16','x17','x18','x19','x20',\n",
    "    'x21','x22','x23','x24','x25','x26','x27','x29','x30','x31','x32','x33','x34','x35','x36','x37','x38','x39','x40',\n",
    "    'x41','x42','x43','x44','x45','x46','x47','x48','x49','x50','x51','x52','x53','x54','x55','x56','x57','x58','x59','x60',\n",
    "    ]\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "for col in cols:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18, 2)\n",
    "#    col_ds = pwbds.groupby('time').agg({col:np.median}).reset_index()\n",
    "    sns.lineplot(x=\"time\", y=col, data=pwbds, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c014a",
   "metadata": {},
   "source": [
    "## Cálculo do Remaining Usefull Lifecycle (RUL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef667a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates whith break\n",
    "df_sub = sorted(pwbds[pwbds['y'] == 1]['time'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87afe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to store all days\n",
    "breakSubIdx=0\n",
    "breakLstIdx=0\n",
    "breakList = pwbds['y'].tolist()\n",
    "nextbreak = []\n",
    "for v1 in pwbds['time'].tolist():\n",
    "    if((breakList[breakLstIdx] == 1)):\n",
    "#        print ('1')\n",
    "        nextbreak.append(v1)\n",
    "        breakSubIdx = breakSubIdx+1\n",
    "    else:\n",
    "#        print('0')\n",
    "        if (breakSubIdx < len(df_sub)):\n",
    "            nextbreak.append(df_sub[breakSubIdx])\n",
    "        else:\n",
    "            nextbreak.append(df_sub[breakSubIdx-1])\n",
    "    breakLstIdx = breakLstIdx+1\n",
    "pwbds['nextbreaktime'] = pd.Series(nextbreak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds['RUL']=round((pwbds['nextbreaktime']-pwbds['time']).dt.total_seconds()/60,2)\n",
    "pwbds.drop(pwbds[pwbds.RUL < 0].index, inplace=True)\n",
    "pwbds.drop(['time','nextbreaktime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c0a62",
   "metadata": {},
   "source": [
    "## Marcação de falha no próximo período (próxima hora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11757518",
   "metadata": {},
   "source": [
    "Using RUL, we can create a label indicating time to failure. We define a boolean (True\\False) value for NEXT_H indicating the engine will fail within 60 minutes (RUL  <=60 ). \n",
    "\n",
    "We can also define a multiclass MULTI  ∈{0,1,2}  indicating {Healthy, RUL <=60, RUL <=120} minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds['NEXT_H'] = np.where(pwbds['RUL'] <= 60, 1, 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb089",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds['NEXT_H'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bb14a",
   "metadata": {},
   "source": [
    "# Feature Selection and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "# List of considered Features\n",
    "FEATURES = [\n",
    "    'x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11','x13','x14','x15','x17','x18','x19','x20',\n",
    "    'x21','x22','x24','x26','x27','x28','x29','x30','x32','x33','x34','x35','x36','x37','x38','x39','x40',\n",
    "    'x41','x42','x43','x44','x45','x46','x47','x48','x49','x50','x54','x55','x56','x57','x60',\n",
    "    ]\n",
    "\n",
    "# Create the dataset with features and filter the data to the list of FEATURES\n",
    "pwbds_filtered = pwbds[FEATURES]\n",
    "\n",
    "# Print the tail of the dataframe\n",
    "pwbds_filtered.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65250f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Scaler removes the median and scales the data according to the quantile range to normalize the price data \n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler \n",
    "\n",
    "# Get the number of rows in the data\n",
    "nrows = pwbds_filtered.shape[0]\n",
    "\n",
    "# Convert the data to numpy values\n",
    "np_data_unscaled = np.array(pwbds_filtered)\n",
    "np_data = np.reshape(np_data_unscaled, (nrows, -1))\n",
    "print(np_data.shape)\n",
    "\n",
    "# Transform the data by scaling each feature to a range between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "np_data_scaled = scaler.fit_transform(np_data_unscaled)\n",
    "pwbds_scaled = pd.DataFrame(\n",
    "    np_data_scaled,\n",
    "    columns=FEATURES\n",
    ")\n",
    "pwbds_scaled['RUL'] = pwbds['RUL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd709b30",
   "metadata": {},
   "source": [
    "# Shaping & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_data_transform(x_data, y_data, num_steps=5):\n",
    "    \"\"\" Changes data to the format for LSTM training for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + num_steps\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        # Get only the last element of the sequency for y\n",
    "        seq_y = y_data[end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490e1cb",
   "metadata": {},
   "source": [
    "## Dataset for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds_m1 = pwbds_scaled.copy()\n",
    "#pwbds_m1.drop('NEXT_H',axis='columns', inplace=True)\n",
    "yds_m1 = pwbds_m1.pop('RUL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = pwbds_m1.shape[1]\n",
    "x_new, y_new = lstm_data_transform(pwbds_m1, yds_m1, num_steps=num_steps)\n",
    "print (\"The new shape of x is\", x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(0.8 * pwbds.shape[0])\n",
    "x_train = x_new[:train_ind]\n",
    "y_train = y_new[:train_ind]\n",
    "x_test = x_new[train_ind:]\n",
    "y_test = y_new[train_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf4056",
   "metadata": {},
   "source": [
    "# Modeling 1: Regression - Predict RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fa9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7521c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.Sequential()\n",
    "model_1.add(layers.LSTM(100, activation='tanh', input_shape=(num_steps, x_train.shape[2]), \n",
    "               return_sequences=True))\n",
    "# Plus a 20% dropout rate\n",
    "model_1.add(layers.Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model_1.add(layers.LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model_1.add(layers.Dropout(0.2))\n",
    "model_1.add(layers.Dense(units=50, activation='relu'))\n",
    "model_1.add(layers.Dense(units=1, activation='linear'))\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model_1.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb08496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the architecture \n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping Callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "history_m1 = model_1.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=40,\n",
    "    callbacks=[callback]\n",
    "#    batch_size=200, \n",
    "#    validation_split=0.10 # Use 10% of data to evaluate the loss. (val_loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot History\n",
    "pd.DataFrame(history_m1.history).plot()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc693072",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 6), dpi=80)\n",
    "plt.plot(y_test,'r+')\n",
    "plt.plot(test_predict,'b+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# use Deep SHAP to explain test set predictions\n",
    "#deep_explainer = shap.DeepExplainer(model_1.predict_proba, x_train)\n",
    "#deep_shap_values = deep_explainer.shap_values(x_test)\n",
    "#shap.force_plot(deep_explainer.expected_value[1], deep_shap_values[1], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b977ab",
   "metadata": {},
   "source": [
    "## Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b341ea13",
   "metadata": {},
   "source": [
    "### Quantas quebras realmente ocorreram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe590437",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test==0,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70555c4",
   "metadata": {},
   "source": [
    "### Quando ocorreram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "break_moments= np.where(y_test == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(break_moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c317b2",
   "metadata": {},
   "source": [
    "## Previsões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612a8e3",
   "metadata": {},
   "source": [
    "### Quantas indicações abaixo de x minutos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_predict < 60 ,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94421ec",
   "metadata": {},
   "source": [
    "### Quando ocorreram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(test_predict < 60)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc437a5",
   "metadata": {},
   "source": [
    "## Acertos\n",
    "### Quantos e quando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "when_pred = np.where(test_predict < 240)[0].tolist()\n",
    "when_true = np.where(y_test == 0)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284540b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonalities = set(when_pred) - (set(when_pred) - set(when_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe7672",
   "metadata": {},
   "source": [
    "# Modeling 2: Binary Classification - Break in the next hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d2271",
   "metadata": {},
   "source": [
    "## Dataset for model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab24ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwbds_m2 = pwbds\n",
    "yds_m2 = pwbds_m2.pop('NEXT_H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87961fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = pwbds_m2.shape[1]\n",
    "x_new, y_new = lstm_data_transform(pwbds_m2, yds_m2, num_steps=num_steps)\n",
    "print (\"The new shape of x is\", x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95639f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(0.8 * pwbds.shape[0])\n",
    "x_train = x_new[:train_ind]\n",
    "y_train = y_new[:train_ind]\n",
    "x_test = x_new[train_ind:]\n",
    "y_test = y_new[train_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5f876",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Sequential()\n",
    "model_2.add(layers.LSTM(100, activation='tanh', input_shape=(num_steps, x_train.shape[2]), \n",
    "               return_sequences=True))\n",
    "# Plus a 20% dropout rate\n",
    "model_2.add(layers.Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model_2.add(layers.LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model_2.add(layers.Dropout(0.2))\n",
    "model_2.add(layers.Dense(units=50, activation='relu'))\n",
    "model_2.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "model_2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_m2 = model_2.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=20,\n",
    "    callbacks=[callback]\n",
    "#    batch_size=200, # \n",
    "#    validation_split=0.10 # Use 10% of data to evaluate the loss. (val_loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e32bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot History\n",
    "pd.DataFrame(history_m2.history).plot()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e521b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_2 = model_2.evaluate(x_test, y_test, verbose=1, batch_size=200)\n",
    "scores_2 = model_2.evaluate(x_test, y_test, verbose=1)\n",
    "print('Training Accurracy: {}'.format(scores_2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbdab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "#y_pred = model_2.predict_classes(x_test,verbose=1, batch_size=200)\n",
    "y_pred = model_2.predict_classes(x_test,verbose=1)\n",
    "y_true = y_test\n",
    "print('Training Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "precision_test = precision_score(y_true, y_pred)\n",
    "recall_test = recall_score(y_true, y_pred)\n",
    "f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
    "print( 'Test Precision: ', precision_test, '\\n', 'Test Recall: ', recall_test, '\\n', 'Test F1 Score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9638f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f19946",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_true, y_pred),\n",
    "    index=['true:0', 'true:1'], \n",
    "    columns=['pred:0', 'pred:1']\n",
    ")\n",
    "print(cmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472b959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper3",
   "language": "python",
   "name": "paper3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
